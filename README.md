# Sara AI â€” Local Assistant (v1.5)

Sara AI is a fully local personal assistant featuring:
- FastAPI backend with modularized pipeline, persona, routing, and memory engines  
- Local LLM text generation (via Ollama)  
- Long-term memory (SQLite)  
- Kokoro TTS (local)  
- Modern React/Vite frontend  

Version **1.5** introduces a complete backend rewrite and modular architecture to support future upgrades (v2.0, v2.5, v3.5+).

---

## ğŸŒŸ Features (v1.5)

### ğŸ”§ **Modular Backend Architecture**
A fully refactored backend using clean modules for:
- Pipeline  
- Router  
- Memory system  
- Persona system  
- TTS  
- Multiple LLM wrappers  

### ğŸ¤¹ **Multi-Model Routing**
Sara now automatically selects between specialized models:
- **Casual model**  
- **Coding model**  
- **Teaching model**  
- **Fast-talking model** (short latency replies)

### ğŸ§  **Improved Long-term Memory**
- Uses `MemoryManager` and `memory_utils`  
- Structured memory formatting  
- Injects relevant context into model prompts  
- Memory panel UI works identically

### ğŸ§¬ **Enhanced Persona Engine**
Modes:
- Gremlin  
- Teaching  
- Professional  

Toggles:
- Child Mode  
- Emojis  
- Formal Tone  

Sliders:
- Swear level  
- Roast level  
- Verbosity  
- Spontaneity  

All persona filters are applied to **any** model automatically.

### ğŸ™ï¸ **Kokoro TTS Integrated Cleanly**
- Stable audio caching
- Accessible audio URLs
- Ready for future â€œTalking Modeâ€ upgrades

### ğŸ’ **Stable & Clean Frontend**
Frontend required **no changes** for v1.5.  
It remains fully compatible with the new backend.

---

## ğŸ§± Architecture Overview (v1.5)

```md
Frontend (React)
â”œâ”€â”€ Chat UI (ChatBubble, InputBar)
â”œâ”€â”€ Persona Panel
â”œâ”€â”€ Memory Panel
â””â”€â”€ saraApi.js â†’ backend calls

Backend (FastAPI, Modular)
â”œâ”€â”€ core/
â”‚   â”œâ”€â”€ pipeline.py          â†’ Central orchestrator
â”‚   â”œâ”€â”€ sara_router.py       â†’ Model routing logic
â”‚   â””â”€â”€ sara_persona.py      â†’ Persona engine
â”‚
â”œâ”€â”€ models/
â”‚   â”œâ”€â”€ local_casual.py
â”‚   â”œâ”€â”€ local_coding.py
â”‚   â”œâ”€â”€ local_teaching.py
â”‚   â””â”€â”€ fast_talking.py
â”‚
â”œâ”€â”€ memory/
â”‚   â”œâ”€â”€ memory_core.py
â”‚   â””â”€â”€ memory_utils.py
â”‚
â”œâ”€â”€ tts/
â”‚   â””â”€â”€ kokoro_tts.py
â”‚
â”œâ”€â”€ persona_store.py
â””â”€â”€ server.py â†’ REST endpoints

Local Runtime
â”œâ”€â”€ Ollama (LLM)
â””â”€â”€ Kokoro (TTS)
````

---

## ğŸ§  Memory System (v1.5)

Sara automatically extracts and stores structured facts:

* â€œMy name is Xâ€ â†’ **relation**
* â€œI like Yâ€ â†’ **preference**
* â€œI am Zâ€ â†’ **identity**
* Other things â†’ **generic fact**

Memory is fetched and injected into model prompts.

---

## ğŸ™ï¸ TTS System (Kokoro)

Sara uses **Kokoro 82M** locally to generate `.wav` files stored in:

```
backend/audio_cache/
```

The backend returns URLs like:

```
/audio/tts_<unique>.wav
```

Frontend auto-plays the audio.

---

## ğŸ§© API Summary

### **POST /api/chat**

Returns text + audio:

```json
{
  "reply": "Hello!",
  "audio_url": "/audio/tts_170000.wav",
  "memory_update": false,
  "model_used": "local_casual"
}
```

### **POST /api/chat_stream**

Text streaming endpoint.

### **POST /api/tts**

Free-form TTS generation.

### **GET/POST /api/persona**

Persona sync.

### **GET /api/memory**

Full memory list.

---

## ğŸ“‚ Folder Structure (v1.5)

```
SaraAI/
â”‚â”€â”€ backend/
â”‚   â”œâ”€â”€ core/
â”‚   â”œâ”€â”€ models/
â”‚   â”œâ”€â”€ memory/
â”‚   â”œâ”€â”€ tts/
â”‚   â”œâ”€â”€ persona_store.py
â”‚   â”œâ”€â”€ server.py
â”‚   â””â”€â”€ __init__.py
â”‚
â”‚â”€â”€ frontend/
â”‚   â”œâ”€â”€ src/
â”‚   â””â”€â”€ assets/
â”‚
â”‚â”€â”€ system_prompt.txt
â”‚â”€â”€ few_shot_examples.txt
â”‚â”€â”€ README.md
```

---

## ğŸš€ Roadmap (official from project document)

This README references the project roadmap file for exact milestone definitions (see project docs). Summary below:

* **v1.0 â€” Core local assistant** (foundation)
* **v1.5 â€” Stability & multi-model routing** (this release)
* **v2.0 â€” Cloud deployment & portfolio demo** (move backend to cloud, hosted DB, secure demo)
* **v2.5 â€” Advanced utilities (web scraping + video editing)** (hybrid features, heavy-job pods)
* **v3.0 â€” System testing & optimization (stress testing)** (load tests, profiling, reliability)
* **v3.5 â€” PNG avatar & UI redesign** (static avatar + emotion variants)
* **v4.0 â€” Live2D integration & streaming (VTuber)** (rigging, mouth-sync, OBS integration)

(Full roadmap sourced from project roadmap file.) 

---

## âš ï¸ Notes

* This assistant is for **local personal use**.
* No installation script is included by design.

```

---

I updated the roadmap to match your uploaded roadmap exactly and added the citation so anyone reading the README knows the source. :contentReference[oaicite:2]{index=2}

Next step if you want to finalize the release:

- I can provide the exact git commands to commit README and push the v1.5 tag.
- Or I can make a small CHANGELOG.md (optional).

Say one of:

- **â€œcommit and tag v1.5â€** â€” Iâ€™ll give the git commands and a commit message.
- **â€œmake CHANGELOG.md and commitâ€** â€” Iâ€™ll provide changelog content and the commands.
- **â€œnot yetâ€** â€” Iâ€™ll wait.
```

